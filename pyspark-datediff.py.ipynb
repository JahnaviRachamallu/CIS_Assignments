{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\n\n# Create SparkSession\nspark = SparkSession.builder \\\n          .appName('SparkByExamples.com') \\\n          .getOrCreate()\ndata = [(\"1\",\"2019-07-01\"),(\"2\",\"2019-06-24\"),(\"3\",\"2019-08-24\")]\n\ndf=spark.createDataFrame(data=data,schema=[\"id\",\"date\"])\n\nfrom pyspark.sql.functions import *\n\ndf.select(\n      col(\"date\"),\n      current_date().alias(\"current_date\"),\n      datediff(current_date(),col(\"date\")).alias(\"datediff\")\n    ).show()\n\ndf.withColumn(\"datesDiff\", datediff(current_date(),col(\"date\"))) \\\n  .withColumn(\"montsDiff\", months_between(current_date(),col(\"date\"))) \\\n  .withColumn(\"montsDiff_round\",round(months_between(current_date(),col(\"date\")),2)) \\\n  .withColumn(\"yearsDiff\",months_between(current_date(),col(\"date\"))/lit(12)) \\\n  .withColumn(\"yearsDiff_round\",round(months_between(current_date(),col(\"date\"))/lit(12),2)) \\\n  .show()\n\ndata2 = [(\"1\",\"07-01-2019\"),(\"2\",\"06-24-2019\"),(\"3\",\"08-24-2019\")]  \ndf2=spark.createDataFrame(data=data2,schema=[\"id\",\"date\"])\ndf2.select(\n    to_date(col(\"date\"),\"MM-dd-yyyy\").alias(\"date\"),\n    current_date().alias(\"endDate\")\n    )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"0166d33d-7251-4f0d-af26-4fdf1dee8b19","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----------+------------+--------+\n|      date|current_date|datediff|\n+----------+------------+--------+\n|2019-07-01|  2023-06-20|    1450|\n|2019-06-24|  2023-06-20|    1457|\n|2019-08-24|  2023-06-20|    1396|\n+----------+------------+--------+\n\n+---+----------+---------+-----------+---------------+------------------+---------------+\n| id|      date|datesDiff|  montsDiff|montsDiff_round|         yearsDiff|yearsDiff_round|\n+---+----------+---------+-----------+---------------+------------------+---------------+\n|  1|2019-07-01|     1450|47.61290323|          47.61|3.9677419358333332|           3.97|\n|  2|2019-06-24|     1457|47.87096774|          47.87|3.9892473116666665|           3.99|\n|  3|2019-08-24|     1396|45.87096774|          45.87|       3.822580645|           3.82|\n+---+----------+---------+-----------+---------------+------------------+---------------+\n\nOut[1]: DataFrame[date: date, endDate: date]"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bdd2a189-526e-440b-a99b-f18cabce1ae7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-datediff.py","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
