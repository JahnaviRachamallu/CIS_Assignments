{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import explode, flatten\n\n\nspark = SparkSession.builder.appName('pyspark-by-examples').getOrCreate()\n\narrayArrayData = [\n  (\"James\",[[\"Java\",\"Scala\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Michael\",[[\"Spark\",\"Java\",\"C++\"],[\"Spark\",\"Java\"]]),\n  (\"Robert\",[[\"CSharp\",\"VB\"],[\"Spark\",\"Python\"]])\n]\n\ndf = spark.createDataFrame(data=arrayArrayData, schema = ['name','subjects'])\ndf.printSchema()\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3e1eab32-aa6b-4a30-b1f0-8f857db01d50","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- name: string (nullable = true)\n |-- subjects: array (nullable = true)\n |    |-- element: array (containsNull = true)\n |    |    |-- element: string (containsNull = true)\n\n+-------+-----------------------------------+\n|name   |subjects                           |\n+-------+-----------------------------------+\n|James  |[[Java, Scala, C++], [Spark, Java]]|\n|Michael|[[Spark, Java, C++], [Spark, Java]]|\n|Robert |[[CSharp, VB], [Spark, Python]]    |\n+-------+-----------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df3 = df.select(df.name,explode(\"subjects\")).show(truncate=False)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"34eb6d40-6cbb-47d9-85de-b76b56847dd9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+------------------+\n|name   |col               |\n+-------+------------------+\n|James  |[Java, Scala, C++]|\n|James  |[Spark, Java]     |\n|Michael|[Spark, Java, C++]|\n|Michael|[Spark, Java]     |\n|Robert |[CSharp, VB]      |\n|Robert |[Spark, Python]   |\n+-------+------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["df.select(df.name,flatten(df.subjects)).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f5cbe297-2852-420d-918f-703e9ab5d98f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------+-------------------------------+\n|name   |flatten(subjects)              |\n+-------+-------------------------------+\n|James  |[Java, Scala, C++, Spark, Java]|\n|Michael|[Spark, Java, C++, Spark, Java]|\n|Robert |[CSharp, VB, Spark, Python]    |\n+-------+-------------------------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c45ce0fe-4c77-4444-afe9-7870a68cc06b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-explode-nested-array","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
